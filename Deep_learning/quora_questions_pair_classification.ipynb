{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u49R_NvnpRDI"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8KC_ytivzPqJ",
    "outputId": "8b5558e1-e645-4991-c846-a2a40106f561"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3GxH6DwvrQg"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MdxO2S6pRDQ"
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "TRAIN_CSV = './data/train.csv'\n",
    "TEST_CSV = './data/test.csv'\n",
    "EMBEDDING_FILE = './data/glove.6B.50d.txt'\n",
    "MODEL_SAVING_DIR = './model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-PCcdtLpRDS"
   },
   "outputs": [],
   "source": [
    "# Load training and test set\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fa38MM-3qa1X",
    "outputId": "0cc979b5-f7e4-4c80-906d-6f724ac20c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH7tBeqCpRDU"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILiWMFi2pRDX"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlwaAtzApRDZ"
   },
   "outputs": [],
   "source": [
    "# Prepare embedding\n",
    "vocabulary = dict()\n",
    "# '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "inverse_vocabulary = ['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYshE_6lpRDb"
   },
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile=EMBEDDING_FILE):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    words = []\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        words.append(word)\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-KFGni-pRDd"
   },
   "outputs": [],
   "source": [
    "word_vecs,vocab = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6_ffhSiQd0u"
   },
   "outputs": [],
   "source": [
    "questions_cols = ['question1', 'question2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ok0fQKDDqyFG"
   },
   "outputs": [],
   "source": [
    "# Iterate over the questions only of both training and test datasets\n",
    "for dataset in [train_df, test_df]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions_cols:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.at[index, question] = q2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_lgp98ipRDe"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "# This will be the embedding matrix\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in vocab:\n",
    "        embeddings[index] = word_vecs[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtF8QgGcsMGF"
   },
   "outputs": [],
   "source": [
    "max_seq_length = max(train_df.question1.map(lambda x: len(x)).max(),\n",
    "                     train_df.question2.map(lambda x: len(x)).max(),\n",
    "                     test_df.question1.map(lambda x: len(x)).max(),\n",
    "                     test_df.question2.map(lambda x: len(x)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JJes29KrxyF0",
    "outputId": "fe19b44b-13f8-44fd-e66b-005147a2d6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nho62x9sQ9n"
   },
   "outputs": [],
   "source": [
    "# Split to train validation\n",
    "validation_size = 40000\n",
    "training_size = len(train_df) - validation_size\n",
    "\n",
    "X = train_df[questions_cols]\n",
    "Y = train_df['is_duplicate']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vur8oKmdx_UQ",
    "outputId": "7aa65d80-a0b2-43b7-8087-f490726db3bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364290"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABZDdYjKsdPG"
   },
   "outputs": [],
   "source": [
    "# Split to dicts\n",
    "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
    "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
    "X_test = {'left': test_df.question1, 'right': test_df.question2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6c-oj-IKaHuk"
   },
   "outputs": [],
   "source": [
    "X_test = {'left': test_df.question1, 'right': test_df.question2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpdkLT8bsf0s"
   },
   "outputs": [],
   "source": [
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CyCSf9bspJI"
   },
   "outputs": [],
   "source": [
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLF4ZptksO8b"
   },
   "outputs": [],
   "source": [
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPS9f3UjvyjP"
   },
   "source": [
    "# Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knTF_n_1wQos"
   },
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.X['left'][idx]\n",
    "        x2 = self.X['right'][idx]\n",
    "        return [x1,x2], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Vh0N94z9Nd2"
   },
   "outputs": [],
   "source": [
    "train_ds = QuoraDataset(X_train, Y_train)\n",
    "valid_ds = QuoraDataset(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "k3nvwT-9-eIJ",
    "outputId": "04d5d947-529f-4ec1-8399-f80c09971830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,    18,\n",
       "           405,  3438,  1596,    14,  1013,  1867,     2,  1013,   802,\n",
       "           329,     9,    24,  2950,    45,    18,  1107,     7,   464,\n",
       "           112,  1945,     9,   528,  1478,     9,     3,  2027,    14,\n",
       "          2766, 14604], dtype=int32),\n",
       "  array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,   184,\n",
       "           802,  1269,    18,  5571,  1270, 18729,     9,    67,    18,\n",
       "         11076,  3172,   950,   802,  1269,   422,    14, 42702,    67,\n",
       "          1454,    18,   183,  3172,     2,    50, 18434,  2220,   171,\n",
       "           712,  1454], dtype=int32)],\n",
       " 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhfP4Dpcv32I"
   },
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3as0aeCQWpen"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ew2UBs5l0Enr"
   },
   "outputs": [],
   "source": [
    "class Manhattan_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, use_embedding=False, train_embedding=True):\n",
    "        super(Manhattan_LSTM, self).__init__()\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if use_embedding:\n",
    "            self.embedding = nn.Embedding(embedding.shape[0], embedding.shape[1])\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(embedding))\n",
    "            # self.embedding.weight = nn.Parameter(embedding)\n",
    "            self.input_size = embedding.shape[1] # V - Size of embedding vector\n",
    "\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(embedding[0], embedding[1])\n",
    "            self.input_size = embedding[1]\n",
    "\n",
    "        self.embedding.weight.requires_grad = train_embedding\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, num_layers=1, bidirectional=False)\n",
    "        # self.linear = nn.Linear(245, 1)\n",
    "\n",
    "    def exponent_neg_manhattan_distance(self, x1, x2):\n",
    "        return torch.exp(-torch.sum(torch.abs(x1 - x2), dim=1))\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        '''\n",
    "        input           -> (2 x Max. Sequence Length (per batch) x Batch Size)\n",
    "        hidden          -> (2 x Num. Layers * Num. Directions x Batch Size x Hidden Size)\n",
    "        '''\n",
    "\n",
    "        embedded_1 = self.embedding(input1) # L, B, V\n",
    "        embedded_2 = self.embedding(input2) # L, B, V\n",
    "        outputs_1, hidden_1 = self.lstm(embedded_1.permute([1, 0, 2]))\n",
    "        outputs_2, hidden_2 = self.lstm(embedded_2.permute([1, 0, 2]))\n",
    "        tmp = hidden_1[0][0].size()[0]\n",
    "        similarity_scores = self.exponent_neg_manhattan_distance(hidden_1[0][0].view(tmp, -1),\n",
    "                                                                 hidden_2[0][0].view(tmp, -1))\n",
    "        return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLrQAIZN0EqQ"
   },
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQH_npv87rY2"
   },
   "outputs": [],
   "source": [
    "def train_epocs_v0(model, optimizer, train_dl, val_dl, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x1 = x[0].long().cuda()\n",
    "            x2 = x[1].long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x1,x2)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.mse_loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
    "        if i % 2 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jECxvvRh7rb0"
   },
   "outputs": [],
   "source": [
    "def val_metrics_v0(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        x1 = x[0].long().cuda()\n",
    "        x2 = x[1].long().cuda()\n",
    "        y = y.float().cuda()\n",
    "        y_pred = model(x1,x2)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        y_pred_01 = np.where(y_pred.cpu() > 0.5, 1, 0).astype(float)\n",
    "        correct += (y_pred_01 == y.cpu().detach().numpy()).astype(float).sum().item()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIq3dyLw_F5s"
   },
   "outputs": [],
   "source": [
    "batch_size = 4000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QC_VstrsBFF1"
   },
   "outputs": [],
   "source": [
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySzpfUz3_F8U"
   },
   "outputs": [],
   "source": [
    "model = Manhattan_LSTM(hidden_size, embeddings, use_embedding=True, train_embedding=True).cuda()\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "Zpo3cTyN_F_O",
    "outputId": "3891c3e5-384a-49fb-aa94-edb0bb69821e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.124 val loss 0.127 and val accuracy 0.822\n",
      "train loss 0.096 val loss 0.119 and val accuracy 0.837\n",
      "train loss 0.084 val loss 0.116 and val accuracy 0.843\n",
      "train loss 0.076 val loss 0.114 and val accuracy 0.844\n",
      "train loss 0.071 val loss 0.113 and val accuracy 0.846\n",
      "train loss 0.067 val loss 0.113 and val accuracy 0.848\n",
      "train loss 0.063 val loss 0.112 and val accuracy 0.849\n",
      "train loss 0.060 val loss 0.111 and val accuracy 0.851\n",
      "train loss 0.058 val loss 0.111 and val accuracy 0.851\n",
      "train loss 0.056 val loss 0.111 and val accuracy 0.851\n",
      "train loss 0.054 val loss 0.110 and val accuracy 0.851\n",
      "train loss 0.053 val loss 0.110 and val accuracy 0.853\n",
      "train loss 0.051 val loss 0.111 and val accuracy 0.852\n",
      "train loss 0.050 val loss 0.110 and val accuracy 0.854\n",
      "train loss 0.049 val loss 0.110 and val accuracy 0.853\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNRu9D_QKGQW"
   },
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zSiSXr4J3g8"
   },
   "outputs": [],
   "source": [
    "# save_model(model, \"853.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mGj5cgUf_GGa",
    "outputId": "93b9c942-3c94-41c4-e4d9-0807f278e45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.044 val loss 0.108 and val accuracy 0.855\n",
      "train loss 0.043 val loss 0.109 and val accuracy 0.855\n",
      "train loss 0.042 val loss 0.109 and val accuracy 0.855\n",
      "train loss 0.042 val loss 0.109 and val accuracy 0.855\n",
      "train loss 0.041 val loss 0.109 and val accuracy 0.855\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, 0.005)\n",
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uSa8e8Bv_bl"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_qey6F-urjmq",
    "outputId": "4917ed25-7037-4b63-bef8-ff42a8fce0ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 245)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['left'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ke55GCELZaU"
   },
   "outputs": [],
   "source": [
    "for dataset, side in itertools.product([X_test], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "F6vdlKHqLZdT",
    "outputId": "e8778818-cf7a-4a0c-bd10-03fab998db1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,    44,   334,  3867,\n",
       "         335,  1584, 12995,    67,   216,  1584,  6275,  1397,  1667,\n",
       "        1241,   749], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['right'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50EJlHeqiDpN"
   },
   "outputs": [],
   "source": [
    "class QuoraDataset_test(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X['right'].shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.X['left'][idx]\n",
    "        x2 = self.X['right'][idx]\n",
    "        return x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqqTXAAAiDz7"
   },
   "outputs": [],
   "source": [
    "test_ds = QuoraDataset_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zx5xpJ4Dr-9D",
    "outputId": "466da916-e30a-48f7-c6af-47f7f2ffe800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4crWKN4iS1L"
   },
   "outputs": [],
   "source": [
    "batch_size_test = 4000\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BVrJww8BPmSf",
    "outputId": "ebdcd7e7-6c61-40c2-92f2-4863cca880bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manhattan_LSTM(\n",
       "  (embedding): Embedding(121322, 50)\n",
       "  (lstm): LSTM(50, 10)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Manhattan_LSTM(hidden_size, embeddings, use_embedding=True, train_embedding=True).cuda()\n",
    "model.load_state_dict(torch.load('/content/853.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIP4Kl4EOwx2"
   },
   "outputs": [],
   "source": [
    "def get_prediction(model, test_dl):\n",
    "    y_pred_total = []\n",
    "    model.eval()\n",
    "    for x in test_dl:\n",
    "        x1 = x[0].long().cuda()\n",
    "        x2 = x[1].long().cuda()\n",
    "        y_pred = model(x1,x2).cpu().detach().numpy()\n",
    "        y_pred_total.append(y_pred)\n",
    "    return y_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgXwIbzIOw07"
   },
   "outputs": [],
   "source": [
    "y_pred_total = get_prediction(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7xQD545pOw4s",
    "outputId": "01ce1627-71f7-4b4d-cdb3-528962207bc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUYmM2FJtJ4o"
   },
   "outputs": [],
   "source": [
    "test = np.concatenate(y_pred_total,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ugrC7iEMtW0T",
    "outputId": "b581ac5a-42d3-43b8-a7f2-a6657d6e6935"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796,)"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dX8zvXllupOK"
   },
   "outputs": [],
   "source": [
    "id = np.arange(0,2345796).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMYQTmBiMihc"
   },
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({'test_id':id, 'is_duplicate':test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zS4l6tZ_Mifd",
    "outputId": "62a84887-a723-42eb-cb91-5f24d6a28ce8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.400789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.218805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.400789\n",
       "1        1      0.519538\n",
       "2        2      0.218805\n",
       "3        3      0.000826\n",
       "4        4      0.050586"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKYCIX3cu1HD"
   },
   "outputs": [],
   "source": [
    "sample_df.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2-jingxian.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
